"use strict";(self.webpackChunkpingcap_docs=self.webpackChunkpingcap_docs||[]).push([[6545],{3905:function(e,t,a){a.d(t,{Zo:function(){return d},kt:function(){return m}});var n=a(7294);function o(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function r(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?r(Object(a),!0).forEach((function(t){o(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):r(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,o=function(e,t){if(null==e)return{};var a,n,o={},r=Object.keys(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||(o[a]=e[a]);return o}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(n=0;n<r.length;n++)a=r[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(o[a]=e[a])}return o}var l=n.createContext({}),p=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},d=function(e){var t=p(e.components);return n.createElement(l.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,o=e.mdxType,r=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=p(a),m=o,h=u["".concat(l,".").concat(m)]||u[m]||c[m]||r;return a?n.createElement(h,i(i({ref:t},d),{},{components:a})):n.createElement(h,i({ref:t},d))}));function m(e,t){var a=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var r=a.length,i=new Array(r);i[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:o,i[1]=s;for(var p=2;p<r;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},335:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return p},assets:function(){return d},toc:function(){return c},default:function(){return m}});var n=a(7462),o=a(3366),r=(a(7294),a(3905)),i=["components"],s={title:"Deploy TiDB on Azure AKS",summary:"Learn how to deploy a TiDB cluster on Azure Kubernetes Service (AKS)."},l="Deploy TiDB on Azure AKS",p={unversionedId:"deploy-on-azure-aks",id:"deploy-on-azure-aks",title:"Deploy TiDB on Azure AKS",description:"This document describes how to deploy a TiDB cluster on Azure Kubernetes Service (AKS).",source:"@site/docs/deploy-on-azure-aks.md",sourceDirName:".",slug:"/deploy-on-azure-aks",permalink:"/deploy-on-azure-aks",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/deploy-on-azure-aks.md",tags:[],version:"current",frontMatter:{title:"Deploy TiDB on Azure AKS",summary:"Learn how to deploy a TiDB cluster on Azure Kubernetes Service (AKS)."},sidebar:"mySidebar",previous:{title:"Deploy TiDB on GCP GKE",permalink:"/deploy-on-gcp-gke"},next:{title:"Deploy TiDB on Alibaba Cloud Kubernetes",permalink:"/deploy-on-alibaba-cloud"}},d={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Create an AKS cluster and a node pool",id:"create-an-aks-cluster-and-a-node-pool",level:2},{value:"Create an AKS cluster with CSI enabled",id:"create-an-aks-cluster-with-csi-enabled",level:3},{value:"Create component node pools",id:"create-component-node-pools",level:3},{value:"Deploy component node pools in availability zones",id:"deploy-component-node-pools-in-availability-zones",level:3},{value:"Deploy",id:"deploy",level:3},{value:"View the cluster status",id:"view-the-cluster-status",level:3},{value:"Access the database",id:"access-the-database",level:2},{value:"Access method",id:"access-method",level:3},{value:"Access via the MySQL client",id:"access-via-the-mysql-client",level:3},{value:"Access the Grafana monitoring dashboard",id:"access-the-grafana-monitoring-dashboard",level:2},{value:"Access TiDB Dashboard",id:"access-tidb-dashboard",level:2},{value:"Upgrade",id:"upgrade",level:2},{value:"Scale out",id:"scale-out",level:2},{value:"Scale out AKS node pool",id:"scale-out-aks-node-pool",level:3},{value:"Scale out TiDB components",id:"scale-out-tidb-components",level:3},{value:"Deploy TiFlash/TiCDC",id:"deploy-tiflashticdc",level:2},{value:"Add node pools",id:"add-node-pools",level:3},{value:"Configure and deploy",id:"configure-and-deploy",level:3},{value:"Deploy TiDB Enterprise Edition",id:"deploy-tidb-enterprise-edition",level:2},{value:"Use other Disk volume types",id:"use-other-disk-volume-types",level:2},{value:"Use local storage",id:"use-local-storage",level:2}],u={toc:c};function m(e){var t=e.components,a=(0,o.Z)(e,i);return(0,r.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"deploy-tidb-on-azure-aks"},"Deploy TiDB on Azure AKS"),(0,r.kt)("p",null,"This document describes how to deploy a TiDB cluster on Azure Kubernetes Service (AKS)."),(0,r.kt)("p",null,"To deploy TiDB Operator and the TiDB cluster in a self-managed Kubernetes environment, refer to ",(0,r.kt)("a",{parentName:"p",href:"/deploy-tidb-operator"},"Deploy TiDB Operator")," and ",(0,r.kt)("a",{parentName:"p",href:"/deploy-on-general-kubernetes"},"Deploy TiDB in General Kubernetes"),"."),(0,r.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("p",null,"Before deploying a TiDB cluster on Azure AKS, perform the following operations:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Install ",(0,r.kt)("a",{parentName:"p",href:"https://helm.sh/docs/intro/install/"},"Helm 3")," for deploying TiDB Operator.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/tutorial-kubernetes-deploy-cluster"},"Deploy a Kubernetes (AKS) cluster")," and install and configure ",(0,r.kt)("inlineCode",{parentName:"p"},"az cli"),"."),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"Note\uff1a")),(0,r.kt)("p",{parentName:"blockquote"},"To verify whether AZ CLI is configured correctly, run the ",(0,r.kt)("inlineCode",{parentName:"p"},"az login")," command. If login with account credentials succeeds, AZ CLI is configured correctly. Otherwise, you need to re-configure AZ CLI."))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Refer to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/use-ultra-disks"},"use Ultra disks")," to create a new cluster that can use Ultra disks or enable Ultra disks in an exist cluster.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Acquire ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/concepts-identity#aks-service-permissions"},"AKS service permissions"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"If the Kubernetes version of the cluster is earlier than 1.21, install ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/custom-node-configuration#install-aks-preview-cli-extension"},"aks-preview CLI extension")," for using Ultra Disks and register ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/csi-storage-drivers#install-csi-storage-drivers-on-a-new-cluster-with-version--121"},"EnableAzureDiskFileCSIDriver")," in ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/cli/azure/feature?view=azure-cli-latest#az_feature_register-optional-parameters"},"your subscription"),"."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Install the aks-preview CLI extension:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az extension add --name aks-preview\n"))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Register ",(0,r.kt)("inlineCode",{parentName:"p"},"EnableAzureDiskFileCSIDriver"),":"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az feature register --name EnableAzureDiskFileCSIDriver --namespace Microsoft.ContainerService --subscription ${your-subscription-id}\n")))))),(0,r.kt)("h2",{id:"create-an-aks-cluster-and-a-node-pool"},"Create an AKS cluster and a node pool"),(0,r.kt)("p",null,"Most of the TiDB cluster components use Azure disk as storage. According to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-cluster-isolation"},"AKS Best Practices"),", when creating an AKS cluster, it is recommended to ensure that each node pool uses one availability zone (at least 3 in total)."),(0,r.kt)("h3",{id:"create-an-aks-cluster-with-csi-enabled"},"Create an AKS cluster with CSI enabled"),(0,r.kt)("p",null,"To create an AKS cluster with ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/csi-storage-drivers"},"CSI enabled"),", run the following command:"),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"If the Kubernetes version of the cluster is earlier than 1.21, you need to append an ",(0,r.kt)("inlineCode",{parentName:"p"},"--aks-custom-headers")," flag to enable the ",(0,r.kt)("strong",{parentName:"p"},"EnableAzureDiskFileCSIDriver")," feature by running the following command:"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"# create AKS cluster\naz aks create \\\n    --resource-group ${resourceGroup} \\\n    --name ${clusterName} \\\n    --location ${location} \\\n    --generate-ssh-keys \\\n    --vm-set-type VirtualMachineScaleSets \\\n    --load-balancer-sku standard \\\n    --node-count 3 \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true\n")),(0,r.kt)("h3",{id:"create-component-node-pools"},"Create component node pools"),(0,r.kt)("p",null,"After creating an AKS cluster, run the following commands to create component node pools. Each node pool may take two to five minutes to create. It is recommended to enable ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/use-ultra-disks#enable-ultra-disks-on-an-existing-cluster"},"Ultra disks")," in the TiKV node pool. For more details about cluster configuration, refer to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/cli/azure/aks?view=azure-cli-latest#az_aks_create"},(0,r.kt)("inlineCode",{parentName:"a"},"az aks")," documentation")," and ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/cli/azure/aks/nodepool?view=azure-cli-latest"},(0,r.kt)("inlineCode",{parentName:"a"},"az aks nodepool")," documentation"),"."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"To create a TiDB Operator and monitor pool:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name admin \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 1 \\\n    --labels dedicated=admin\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a PD node pool with ",(0,r.kt)("inlineCode",{parentName:"p"},"nodeType")," being ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_F4s_v2")," or higher:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name pd \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 3 \\\n    --labels dedicated=pd \\\n    --node-taints dedicated=pd:NoSchedule\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a TiDB node pool with ",(0,r.kt)("inlineCode",{parentName:"p"},"nodeType")," being ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_F8s_v2")," or higher. You can set ",(0,r.kt)("inlineCode",{parentName:"p"},"--node-count")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"2")," because only two TiDB nodes are required by default. You can also scale out this node pool by modifying this parameter at any time if necessary."),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tidb \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 2 \\\n    --labels dedicated=tidb \\\n    --node-taints dedicated=tidb:NoSchedule\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a TiKV node pool with ",(0,r.kt)("inlineCode",{parentName:"p"},"nodeType")," being ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_E8s_v4")," or higher:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tikv \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 3 \\\n    --labels dedicated=tikv \\\n    --node-taints dedicated=tikv:NoSchedule \\\n    --enable-ultra-ssd\n")))),(0,r.kt)("h3",{id:"deploy-component-node-pools-in-availability-zones"},"Deploy component node pools in availability zones"),(0,r.kt)("p",null,'The Azure AKS cluster deploys nodes across multiple zones using "best effort zone balance". If you want to apply "strict zone balance" (not supported in AKS now), you can deploy one node pool in one zone. For example:'),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create TiKV node pool 1 in zone 1:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tikv1 \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 1 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 1 \\\n    --labels dedicated=tikv \\\n    --node-taints dedicated=tikv:NoSchedule \\\n    --enable-ultra-ssd\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create TiKV node pool 2 in zone 2:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tikv2 \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 2 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 1 \\\n    --labels dedicated=tikv \\\n    --node-taints dedicated=tikv:NoSchedule \\\n    --enable-ultra-ssd\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create TiKV node pool 3 in zone 3:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tikv3 \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 1 \\\n    --labels dedicated=tikv \\\n    --node-taints dedicated=tikv:NoSchedule \\\n    --enable-ultra-ssd\n")))),(0,r.kt)("div",{className:"admonition admonition-danger alert alert--danger"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"12",height:"16",viewBox:"0 0 12 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M5.05.31c.81 2.17.41 3.38-.52 4.31C3.55 5.67 1.98 6.45.9 7.98c-1.45 2.05-1.7 6.53 3.53 7.7-2.2-1.16-2.67-4.52-.3-6.61-.61 2.03.53 3.33 1.94 2.86 1.39-.47 2.3.53 2.27 1.67-.02.78-.31 1.44-1.13 1.81 3.42-.59 4.78-3.42 4.78-5.56 0-2.84-2.53-3.22-1.25-5.61-1.52.13-2.03 1.13-1.89 2.75.09 1.08-1.02 1.8-1.86 1.33-.67-.41-.66-1.19-.06-1.78C8.18 5.31 8.68 2.45 5.05.32L5.03.3l.02.01z"}))),"Warning")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"About node pool scale-in:"),(0,r.kt)("ul",{parentName:"div"},(0,r.kt)("li",{parentName:"ul"},"You can manually scale in or out an AKS cluster to run a different number of nodes. When you scale in, nodes are carefully ",(0,r.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/"},"cordoned and drained")," to minimize disruption to running applications. Refer to ",(0,r.kt)("a",{parentName:"li",href:"https://docs.microsoft.com/en-us/azure/aks/scale-cluster"},"Scale the node count in an Azure Kubernetes Service (AKS) cluster"),".")),(0,r.kt)("h2",{parentName:"div",id:"configure-storageclass"},"Configure StorageClass"),(0,r.kt)("p",{parentName:"div"},"To improve disk IO performance, it is recommended to add ",(0,r.kt)("inlineCode",{parentName:"p"},"mountOptions")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"StorageClass")," to configure ",(0,r.kt)("inlineCode",{parentName:"p"},"nodelalloc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"noatime"),". Refer to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb/stable/check-before-deployment#mount-the-data-disk-ext4-filesystem-with-options-on-the-target-machines-that-deploy-tikv"},"Mount the data disk ext4 filesystem with options on the target machines that deploy TiKV"),"."),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"kind: StorageClass\napiVersion: storage.k8s.io/v1\n# ...\nmountOptions:\n- nodelalloc,noatime\n")),(0,r.kt)("h2",{parentName:"div",id:"deploy-tidb-operator"},"Deploy TiDB Operator"),(0,r.kt)("p",{parentName:"div"},"Deploy TiDB Operator in the AKS cluster by referring to ",(0,r.kt)("a",{parentName:"p",href:"/get-started#step-2-deploy-tidb-operator"},(0,r.kt)("em",{parentName:"a"},"Deploy TiDB Operator")," section"),"."),(0,r.kt)("h2",{parentName:"div",id:"deploy-a-tidb-cluster-and-the-monitoring-component"},"Deploy a TiDB cluster and the monitoring component"),(0,r.kt)("p",{parentName:"div"},"This section describes how to deploy a TiDB cluster and its monitoring component in Azure AKS."),(0,r.kt)("h3",{parentName:"div",id:"create-namespace"},"Create namespace"),(0,r.kt)("p",{parentName:"div"},"To create a namespace to deploy the TiDB cluster, run the following command:"),(0,r.kt)("pre",{parentName:"div"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl create namespace tidb-cluster\n")))),(0,r.kt)("p",null,"A ",(0,r.kt)("a",{parentName:"p",href:"https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/"},(0,r.kt)("inlineCode",{parentName:"a"},"namespace"))," is a virtual cluster backed by the same physical cluster. This document takes ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster")," as an example. If you want to use other namespaces, modify the corresponding arguments of ",(0,r.kt)("inlineCode",{parentName:"p"},"-n")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"--namespace"),"."),(0,r.kt)("p",null,":::"),(0,r.kt)("h3",{id:"deploy"},"Deploy"),(0,r.kt)("p",null,"First, download the sample ",(0,r.kt)("inlineCode",{parentName:"p"},"TidbCluster")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"TidbMonitor")," configuration files:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"curl -O https://raw.githubusercontent.com/pingcap/tidb-operator/master/examples/aks/tidb-cluster.yaml && \\\ncurl -O https://raw.githubusercontent.com/pingcap/tidb-operator/master/examples/aks/tidb-monitor.yaml\n")),(0,r.kt)("p",null,"Refer to ",(0,r.kt)("a",{parentName:"p",href:"/configure-a-tidb-cluster"},"configure the TiDB cluster")," to further customize and configure the CR before applying."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"By default, TiDB LoadBalancer in ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml"),' is set to "internal", indicating that the LoadBalancer is only accessible within the cluster virtual network, not externally. To access TiDB over the MySQL protocol, you need to use a bastion to access the internal host of the cluster or use ',(0,r.kt)("inlineCode",{parentName:"p"},"kubectl port-forward"),'. You can delete the "internal" schema in the ',(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml")," file to expose the LoadBalancer publicly by default. However, notice that this practice may expose TiDB to risks."))),(0,r.kt)("p",null,"To deploy the ",(0,r.kt)("inlineCode",{parentName:"p"},"TidbCluster")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"TidbMonitor")," CR in the AKS cluster, run the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f tidb-cluster.yaml -n tidb-cluster && \\\nkubectl apply -f tidb-monitor.yaml -n tidb-cluster\n")),(0,r.kt)("p",null,"After the yaml file above is applied to the Kubernetes cluster, TiDB Operator creates the desired TiDB cluster and its monitoring component according to the yaml file."),(0,r.kt)("h3",{id:"view-the-cluster-status"},"View the cluster status"),(0,r.kt)("p",null,"To view the status of the TiDB cluster, run the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl get pods -n tidb-cluster\n")),(0,r.kt)("p",null,"When all the pods are in the ",(0,r.kt)("inlineCode",{parentName:"p"},"Running")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"Ready")," state, the TiDB cluster is successfully started. For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"NAME                              READY   STATUS    RESTARTS   AGE\ntidb-discovery-5cb8474d89-n8cxk   1/1     Running   0          47h\ntidb-monitor-6fbcc68669-dsjlc     3/3     Running   0          47h\ntidb-pd-0                         1/1     Running   0          47h\ntidb-pd-1                         1/1     Running   0          46h\ntidb-pd-2                         1/1     Running   0          46h\ntidb-tidb-0                       2/2     Running   0          47h\ntidb-tidb-1                       2/2     Running   0          46h\ntidb-tikv-0                       1/1     Running   0          47h\ntidb-tikv-1                       1/1     Running   0          47h\ntidb-tikv-2                       1/1     Running   0          47h\n")),(0,r.kt)("h2",{id:"access-the-database"},"Access the database"),(0,r.kt)("p",null,"After deploying a TiDB cluster, you can access the TiDB database to test or develop applications."),(0,r.kt)("h3",{id:"access-method"},"Access method"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Access via Bastion")),(0,r.kt)("p",null,"The LoadBalancer created for your TiDB cluster resides in an intranet. You can create a ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/bastion/tutorial-create-host-portal"},"Bastion")," in the cluster virtual network to connect to an internal host and then access the database."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"In addition to the bastion host, you can also connect an existing host to the cluster virtual network by ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/virtual-network/virtual-network-peering-overview"},"Peering"),". If the AKS cluster is created in an existing virtual network, you can use hosts in this virtual network to access the database."))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Access via SSH")),(0,r.kt)("p",null,"You can ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/ssh#create-the-ssh-connection-to-a-linux-node"},"create the SSH connection to a Linux node")," to access the database."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Access via node-shell")),(0,r.kt)("p",null,"You can simply use tools like ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/kvaps/kubectl-node-shell"},"node-shell")," to connect to nodes in the cluster, then access the database."),(0,r.kt)("h3",{id:"access-via-the-mysql-client"},"Access via the MySQL client"),(0,r.kt)("p",null,"After access to the internal host via SSH, you can access the TiDB cluster through the MySQL client."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Install the MySQL client on the host:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"sudo yum install mysql -y\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Connect the client to the TiDB cluster:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"mysql --comments -h ${tidb-lb-ip} -P 4000 -u root\n")),(0,r.kt)("p",{parentName:"li"},(0,r.kt)("inlineCode",{parentName:"p"},"${tidb-lb-ip}")," is the LoadBalancer IP address of the TiDB service. To obtain it, run the ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get svc basic-tidb -n tidb-cluster")," command. The ",(0,r.kt)("inlineCode",{parentName:"p"},"EXTERNAL-IP")," field returned is the IP address."),(0,r.kt)("p",{parentName:"li"},"For example:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"$ mysql --comments -h 20.240.0.7 -P 4000 -u root\nWelcome to the MariaDB monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 1189\nServer version: 5.7.25-TiDB-v4.0.2 TiDB Server (Apache License 2.0) Community Edition, MySQL 5.7 compatible\n\nCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.\n\nType 'help;' or '\\h' for help. Type '\\c' to clear the current input statement.\n\nMySQL [(none)]> show status;\n+--------------------+--------------------------------------+\n| Variable_name      | Value                                |\n+--------------------+--------------------------------------+\n| Ssl_cipher         |                                      |\n| Ssl_cipher_list    |                                      |\n| Ssl_verify_mode    | 0                                    |\n| Ssl_version        |                                      |\n| ddl_schema_version | 22                                   |\n| server_id          | ed4ba88b-436a-424d-9087-977e897cf5ec |\n+--------------------+--------------------------------------+\n6 rows in set (0.00 sec)\n")))),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("ul",{parentName:"div"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html#sysvar_default_authentication_plugin"},"The default authentication plugin of MySQL 8.0")," is updated from ",(0,r.kt)("inlineCode",{parentName:"li"},"mysql_native_password")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"caching_sha2_password"),". Therefore, if you access the TiDB service (earlier than v4.0.7) by using MySQL 8.0 client via password authentication, you need to specify the ",(0,r.kt)("inlineCode",{parentName:"li"},"--default-auth=mysql_native_password")," parameter."),(0,r.kt)("li",{parentName:"ul"},"By default, TiDB (starting from v4.0.2) periodically shares usage details with PingCAP to help understand how to improve the product. For details about what is shared and how to disable the sharing, see ",(0,r.kt)("a",{parentName:"li",href:"https://docs.pingcap.com/tidb/stable/telemetry"},"Telemetry"),".")))),(0,r.kt)("h2",{id:"access-the-grafana-monitoring-dashboard"},"Access the Grafana monitoring dashboard"),(0,r.kt)("p",null,"Obtain the LoadBalancer IP address of Grafana:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl -n tidb-cluster get svc basic-grafana\n")),(0,r.kt)("p",null,"For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl get svc basic-grafana\nNAME            TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE\nbasic-grafana   LoadBalancer   10.100.199.42   20.240.0.8    3000:30761/TCP   121m\n")),(0,r.kt)("p",null,"In the output above, the ",(0,r.kt)("inlineCode",{parentName:"p"},"EXTERNAL-IP")," column is the LoadBalancer IP address."),(0,r.kt)("p",null,"You can access the ",(0,r.kt)("inlineCode",{parentName:"p"},"${grafana-lb}:3000")," address using your web browser to view monitoring metrics. Replace ",(0,r.kt)("inlineCode",{parentName:"p"},"${grafana-lb}")," with the LoadBalancer IP address."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("p",{parentName:"div"},"The default Grafana username and password are both ",(0,r.kt)("inlineCode",{parentName:"p"},"admin"),"."))),(0,r.kt)("h2",{id:"access-tidb-dashboard"},"Access TiDB Dashboard"),(0,r.kt)("p",null,"See ",(0,r.kt)("a",{parentName:"p",href:"/access-dashboard"},"Access TiDB Dashboard")," for instructions about how to securely allow access to TiDB Dashboard."),(0,r.kt)("h2",{id:"upgrade"},"Upgrade"),(0,r.kt)("p",null,"To upgrade the TiDB cluster, execute the following command:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},'kubectl patch tc basic -n tidb-cluster --type merge -p \'{"spec":{"version":"${version}"}}`.\n')),(0,r.kt)("p",null,"The upgrade process does not finish immediately. You can view the upgrade progress by running the ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl get pods -n tidb-cluster --watch")," command."),(0,r.kt)("h2",{id:"scale-out"},"Scale out"),(0,r.kt)("p",null,"Before scaling out the cluster, you need to scale out the corresponding node pool so that the new instances have enough resources for operation."),(0,r.kt)("p",null,"This section describes how to scale out the AKS node pool and TiDB components."),(0,r.kt)("h3",{id:"scale-out-aks-node-pool"},"Scale out AKS node pool"),(0,r.kt)("p",null,"When scaling out TiKV, the node pools must be scaled out evenly among availability zones. The following example shows how to scale out the TiKV node pool of the ",(0,r.kt)("inlineCode",{parentName:"p"},"${clusterName}")," cluster to 6 nodes:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool scale \\\n    --resource-group ${resourceGroup} \\\n    --cluster-name ${clusterName} \\\n    --name ${nodePoolName} \\\n    --node-count 6\n")),(0,r.kt)("p",null,"For more information on node pool management, refer to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/zh-cn/cli/azure/aks/nodepool?view=azure-cli-latest"},(0,r.kt)("inlineCode",{parentName:"a"},"az aks nodepool")),"."),(0,r.kt)("h3",{id:"scale-out-tidb-components"},"Scale out TiDB components"),(0,r.kt)("p",null,"After scaling out the AKS node pool, run the ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl edit tc basic -n tidb-cluster")," command with ",(0,r.kt)("inlineCode",{parentName:"p"},"replicas")," of each component set to desired value. The scaling-out process is then completed."),(0,r.kt)("h2",{id:"deploy-tiflashticdc"},"Deploy TiFlash/TiCDC"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb/stable/tiflash-overview"},"TiFlash")," is the columnar storage extension of TiKV."),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb/stable/ticdc-overview"},"TiCDC")," is a tool for replicating the incremental data of TiDB by pulling TiKV change logs."),(0,r.kt)("p",null,"The two components are ",(0,r.kt)("em",{parentName:"p"},"not required")," in the deployment. This section shows a quick start example."),(0,r.kt)("h3",{id:"add-node-pools"},"Add node pools"),(0,r.kt)("p",null,"Add a node pool for TiFlash/TiCDC respectively. You can set ",(0,r.kt)("inlineCode",{parentName:"p"},"--node-count")," as required."),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a TiFlash node pool with ",(0,r.kt)("inlineCode",{parentName:"p"},"nodeType")," being ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_E8s_v4")," or higher:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tiflash \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 3 \\\n    --labels dedicated=tiflash \\\n    --node-taints dedicated=tiflash:NoSchedule\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a TiCDC node pool with ",(0,r.kt)("inlineCode",{parentName:"p"},"nodeType")," being ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_E16s_v4")," or higher:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name ticdc \\\n    --cluster-name ${clusterName} \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size ${nodeType} \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 3 \\\n    --labels dedicated=ticdc \\\n    --node-taints dedicated=ticdc:NoSchedule\n")))),(0,r.kt)("h3",{id:"configure-and-deploy"},"Configure and deploy"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"To deploy TiFlash, configure ",(0,r.kt)("inlineCode",{parentName:"p"},"spec.tiflash")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml"),". The following is an example:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"spec:\n  ...\n  tiflash:\n    baseImage: pingcap/tiflash\n    maxFailoverCount: 0\n    replicas: 1\n    storageClaims:\n    - resources:\n        requests:\n          storage: 100Gi\n    tolerations:\n    - effect: NoSchedule\n      key: dedicated\n      operator: Equal\n      value: tiflash\n")),(0,r.kt)("p",{parentName:"li"},"  For other parameters, refer to ",(0,r.kt)("a",{parentName:"p",href:"/configure-a-tidb-cluster"},"Configure a TiDB Cluster"),"."),(0,r.kt)("blockquote",{parentName:"li"},(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("strong",{parentName:"p"},"Warning:")),(0,r.kt)("p",{parentName:"blockquote"},"TiDB Operator automatically mounts PVs ",(0,r.kt)("strong",{parentName:"p"},"in the order of the configuration")," in the ",(0,r.kt)("inlineCode",{parentName:"p"},"storageClaims")," list. Therefore, if you need to add disks for TiFlash, make sure that you add the disks ",(0,r.kt)("strong",{parentName:"p"},"only to the end of the original configuration")," in the list. In addition, you must ",(0,r.kt)("strong",{parentName:"p"},"not")," alter the order of the original configuration."))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"To deploy TiCDC, configure ",(0,r.kt)("inlineCode",{parentName:"p"},"spec.ticdc")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml"),". The following is an example:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"spec:\n  ...\n  ticdc:\n    baseImage: pingcap/ticdc\n    replicas: 1\n    tolerations:\n    - effect: NoSchedule\n      key: dedicated\n      operator: Equal\n      value: ticdc\n")),(0,r.kt)("p",{parentName:"li"},"  Modify ",(0,r.kt)("inlineCode",{parentName:"p"},"replicas")," as required."))),(0,r.kt)("p",null,"Finally, run the ",(0,r.kt)("inlineCode",{parentName:"p"},"kubectl -n tidb-cluster apply -f tidb-cluster.yaml")," command to update the TiDB cluster configuration."),(0,r.kt)("p",null,"For detailed CR configuration, refer to ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/pingcap/tidb-operator/blob/master/docs/api-references/docs.md"},"API references")," and ",(0,r.kt)("a",{parentName:"p",href:"/configure-a-tidb-cluster"},"Configure a TiDB Cluster"),"."),(0,r.kt)("h2",{id:"deploy-tidb-enterprise-edition"},"Deploy TiDB Enterprise Edition"),(0,r.kt)("p",null,"To deploy TiDB/PD/TiKV/TiFlash/TiCDC Enterprise Edition, configure ",(0,r.kt)("inlineCode",{parentName:"p"},"spec.[tidb|pd|tikv|tiflash|ticdc].baseImage")," in ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml")," as the enterprise image. The enterprise image format is ",(0,r.kt)("inlineCode",{parentName:"p"},"pingcap/[tidb|pd|tikv|tiflash|ticdc]-enterprise"),"."),(0,r.kt)("p",null,"For example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"spec:\n  ...\n  pd:\n    baseImage: pingcap/pd-enterprise\n  ...\n  tikv:\n    baseImage: pingcap/tikv-enterprise\n")),(0,r.kt)("h2",{id:"use-other-disk-volume-types"},"Use other Disk volume types"),(0,r.kt)("p",null,"Azure disks support multiple volume types. Among them, ",(0,r.kt)("inlineCode",{parentName:"p"},"UltraSSD")," delivers low latency and high throughput and can be enabled by performing the following steps:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/aks/use-ultra-disks#enable-ultra-disks-on-an-existing-cluster"},"Enable Ultra disks on an existing cluster")," and create a storage class for ",(0,r.kt)("inlineCode",{parentName:"p"},"UltraSSD"),":"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"apiVersion: storage.k8s.io/v1\nkind: StorageClass\nmetadata:\n  name: ultra\nprovisioner: disk.csi.azure.com\nparameters:\n  skuname: UltraSSD_LRS  # alias: storageaccounttype, available values: Standard_LRS, Premium_LRS, StandardSSD_LRS, UltraSSD_LRS\n  cachingMode: None\nreclaimPolicy: Delete\nallowVolumeExpansion: true\nvolumeBindingMode: WaitForFirstConsumer\nmountOptions:\n- nodelalloc,noatime\n")),(0,r.kt)("p",{parentName:"li"},"You can add more ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/azuredisk-csi-driver/blob/master/docs/driver-parameters.md"},"Driver Parameters")," as required.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"In ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml"),", specify the ",(0,r.kt)("inlineCode",{parentName:"p"},"ultra")," storage class to apply for the ",(0,r.kt)("inlineCode",{parentName:"p"},"UltraSSD")," volume type through the ",(0,r.kt)("inlineCode",{parentName:"p"},"storageClassName")," field."),(0,r.kt)("p",{parentName:"li"},"The following is a TiKV configuration example you can refer to:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},"spec:\n  tikv:\n    ...\n    storageClassName: ultra\n")))),(0,r.kt)("p",null,"You can use any supported Azure disk type. It is recommended to use ",(0,r.kt)("inlineCode",{parentName:"p"},"Premium_LRS")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"UltraSSD_LRS"),"."),(0,r.kt)("p",null,"For more information about the storage class configuration and Azure disk types, refer to ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/kubernetes-sigs/azuredisk-csi-driver"},"Storage Class documentation")," and ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/virtual-machines/disks-types"},"Azure Disk Types"),"."),(0,r.kt)("h2",{id:"use-local-storage"},"Use local storage"),(0,r.kt)("p",null,"Use Azure LRS disks for storage in production environment. To simulate bare-metal performance, use additional ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/virtual-machines/sizes-storage"},"NVMe SSD local store volumes")," provided by some Azure instances. You can choose such instances for the TiKV node pool to achieve higher IOPS and lower latency."),(0,r.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,r.kt)("div",{parentName:"div",className:"admonition-heading"},(0,r.kt)("h5",{parentName:"div"},(0,r.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,r.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,r.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,r.kt)("div",{parentName:"div",className:"admonition-content"},(0,r.kt)("ul",{parentName:"div"},(0,r.kt)("li",{parentName:"ul"},"You cannot dynamically change the storage class of a running TiDB cluster. In this case, create a new cluster for testing."),(0,r.kt)("li",{parentName:"ul"},"Local NVMe Disks are ephemeral. Data will be lost on these disks if you stop/deallocate your node. When the node is reconstructed, you need to migrate data in TiKV. If you do not want to migrate data, it is recommended not to use the local disk in a production environment.")))),(0,r.kt)("p",null,"For instance types that provide local disks, refer to ",(0,r.kt)("a",{parentName:"p",href:"https://docs.microsoft.com/en-us/azure/virtual-machines/lsv2-series"},"Lsv2-series"),". The following takes ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_L8s_v2")," as an example:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Create a node pool with local storage for TiKV."),(0,r.kt)("p",{parentName:"li"},"Modify the instance type of the TiKV node pool in the ",(0,r.kt)("inlineCode",{parentName:"p"},"az aks nodepool add")," command to ",(0,r.kt)("inlineCode",{parentName:"p"},"Standard_L8s_v2"),":"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"az aks nodepool add --name tikv \\\n    --cluster-name ${clusterName}  \\\n    --resource-group ${resourceGroup} \\\n    --node-vm-size Standard_L8s_v2 \\\n    --zones 1 2 3 \\\n    --aks-custom-headers EnableAzureDiskFileCSIDriver=true \\\n    --node-count 3 \\\n    --enable-ultra-ssd \\\n    --labels dedicated=tikv \\\n    --node-taints dedicated=tikv:NoSchedule\n")),(0,r.kt)("p",{parentName:"li"},"If the TiKV node pool already exists, you can either delete the old group and then create a new one, or change the group name to avoid conflict.")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Deploy the local volume provisioner."),(0,r.kt)("p",{parentName:"li"},"You need to use the ",(0,r.kt)("a",{parentName:"p",href:"https://sigs.k8s.io/sig-storage-local-static-provisioner"},"local-volume-provisioner")," to discover and manage the local storage. Run the following command to deploy and create a ",(0,r.kt)("inlineCode",{parentName:"p"},"local-storage")," storage class:"),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl apply -f https://raw.githubusercontent.com/pingcap/tidb-operator/master/manifests/eks/local-volume-provisioner.yaml\n"))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},"Use local storage."),(0,r.kt)("p",{parentName:"li"},"After the steps above, the local volume provisioner can discover all the local NVMe SSD disks in the cluster."),(0,r.kt)("p",{parentName:"li"},"Add the ",(0,r.kt)("inlineCode",{parentName:"p"},"tikv.storageClassName")," field to the ",(0,r.kt)("inlineCode",{parentName:"p"},"tidb-cluster.yaml")," file and set the value of the field to ",(0,r.kt)("inlineCode",{parentName:"p"},"local-storage"),"."),(0,r.kt)("p",{parentName:"li"},"For more information, refer to ",(0,r.kt)("a",{parentName:"p",href:"#deploy"},"Deploy TiDB cluster and its monitoring components")))))}m.isMDXComponent=!0}}]);