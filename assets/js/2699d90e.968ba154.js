"use strict";(self.webpackChunkpingcap_docs=self.webpackChunkpingcap_docs||[]).push([[3596],{3905:function(e,t,a){a.d(t,{Zo:function(){return m},kt:function(){return u}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),d=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},m=function(e){var t=d(e.components);return n.createElement(l.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},c=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=d(a),u=r,h=c["".concat(l,".").concat(u)]||c[u]||p[u]||i;return a?n.createElement(h,o(o({ref:t},m),{},{components:a})):n.createElement(h,o({ref:t},m))}));function u(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=c;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var d=2;d<i;d++)o[d]=a[d];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}c.displayName="MDXCreateElement"},7531:function(e,t,a){a.r(t),a.d(t,{frontMatter:function(){return s},contentTitle:function(){return l},metadata:function(){return d},assets:function(){return m},toc:function(){return p},default:function(){return u}});var n=a(7462),r=a(3366),i=(a(7294),a(3905)),o=["components"],s={title:"Use DM in Kubernetes",summary:"Learn how to migrate MySQL data to TiDB cluster using DM in Kubernetes."},l="Use DM in Kubernetes",d={unversionedId:"use-tidb-dm",id:"use-tidb-dm",title:"Use DM in Kubernetes",description:"TiDB Data Migration (DM) is an integrated data migration task management platform that supports the full data migration and the incremental data replication from MySQL/MariaDB into TiDB. This document describes how to migrate MySQL data to TiDB cluster using DM in Kubernetes.",source:"@site/docs/use-tidb-dm.md",sourceDirName:".",slug:"/use-tidb-dm",permalink:"/docusaurus-operator/use-tidb-dm",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/use-tidb-dm.md",tags:[],version:"current",frontMatter:{title:"Use DM in Kubernetes",summary:"Learn how to migrate MySQL data to TiDB cluster using DM in Kubernetes."},sidebar:"mySidebar",previous:{title:"Deploy DM in Kubernetes",permalink:"/docusaurus-operator/deploy-tidb-dm"},next:{title:"Migrate TiDB to Kubernetes",permalink:"/docusaurus-operator/migrate-tidb-to-kubernetes"}},m={},p=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Enable DM data migration tasks",id:"enable-dm-data-migration-tasks",level:2},{value:"Get into the Pod",id:"get-into-the-pod",level:3},{value:"Create data source",id:"create-data-source",level:3},{value:"Configure migration tasks",id:"configure-migration-tasks",level:3},{value:"Start/Check/Stop the migration tasks",id:"startcheckstop-the-migration-tasks",level:3}],c={toc:p};function u(e){var t=e.components,a=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"use-dm-in-kubernetes"},"Use DM in Kubernetes"),(0,i.kt)("p",null,(0,i.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb-data-migration/v2.0"},"TiDB Data Migration")," (DM) is an integrated data migration task management platform that supports the full data migration and the incremental data replication from MySQL/MariaDB into TiDB. This document describes how to migrate MySQL data to TiDB cluster using DM in Kubernetes."),(0,i.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Complete ",(0,i.kt)("a",{parentName:"li",href:"/docusaurus-operator/deploy-tidb-operator"},"deploying TiDB Operator"),"."),(0,i.kt)("li",{parentName:"ul"},"Complete ",(0,i.kt)("a",{parentName:"li",href:"/docusaurus-operator/deploy-tidb-dm"},"deploying DM in Kubernetes"),".")),(0,i.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"Make sure that the TiDB Operator version >= 1.2.0."))),(0,i.kt)("h2",{id:"enable-dm-data-migration-tasks"},"Enable DM data migration tasks"),(0,i.kt)("p",null,"You can access the DM-master service using dmctl in the following two methods:"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Method #1"),": Attach to the DM-master or DM-worker Pod to use the built-in ",(0,i.kt)("inlineCode",{parentName:"p"},"dmctl")," in the image."),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Method #2"),": Expose the DM-master service by ",(0,i.kt)("a",{parentName:"p",href:"/docusaurus-operator/deploy-tidb-dm#access-the-dm-cluster-in-kubernetes"},"accessing the DM cluster in Kubernetes")," and use ",(0,i.kt)("inlineCode",{parentName:"p"},"dmctl")," outside the pods to access the exposed DM-master service."),(0,i.kt)("p",null,"It is recommended to use ",(0,i.kt)("strong",{parentName:"p"},"Method #1")," for migration. The following steps take ",(0,i.kt)("strong",{parentName:"p"},"Method #1")," as an example to introduce how to start a DM data migration task."),(0,i.kt)("p",null,"The differences between Method #1 and Method #2 are that the file locations of ",(0,i.kt)("inlineCode",{parentName:"p"},"source.yaml")," and ",(0,i.kt)("inlineCode",{parentName:"p"},"task.yaml")," are different, and that in Method #2 you need to configure the exposed DM-master service address in the ",(0,i.kt)("inlineCode",{parentName:"p"},"master-addr")," configuration item of ",(0,i.kt)("inlineCode",{parentName:"p"},"dmctl"),"."),(0,i.kt)("h3",{id:"get-into-the-pod"},"Get into the Pod"),(0,i.kt)("p",null,"Attach to the DM-master Pod by executing the following command:"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"kubectl exec -ti ${dm_cluster_name}-dm-master-0 -n ${namespace} - /bin/sh\n")),(0,i.kt)("h3",{id:"create-data-source"},"Create data source"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Write MySQL-1 related information to ",(0,i.kt)("inlineCode",{parentName:"p"},"source1.yaml")," file, which can refer to ",(0,i.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb-data-migration/v2.0/migrate-data-using-dm#step-3-create-data-source"},"Create data source"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Configure the ",(0,i.kt)("inlineCode",{parentName:"p"},"from.host")," in the ",(0,i.kt)("inlineCode",{parentName:"p"},"source1.yaml")," file as the MySQL host address that the Kubernetes cluster can access internally.")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Configure the ",(0,i.kt)("inlineCode",{parentName:"p"},"relay-dir")," in the ",(0,i.kt)("inlineCode",{parentName:"p"},"source1.yaml")," file as a subdirectory of the persistent volume in the Pod mount ",(0,i.kt)("inlineCode",{parentName:"p"},"/var/lib/dm-worker")," directory. For example, ",(0,i.kt)("inlineCode",{parentName:"p"},"/var/lib/dm-worker/relay"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"After you prepare the ",(0,i.kt)("inlineCode",{parentName:"p"},"source1.yaml")," file, load the MySQL-1 data source into the DM cluster by executing the following command:"),(0,i.kt)("pre",{parentName:"li"},(0,i.kt)("code",{parentName:"pre",className:"language-shell"},"/dmctl --master-addr ${dm_cluster_name}-dm-master:8261 operate-source create source1.yaml\n"))),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"For MySQL-2 and other data sources, use the same method to modify the relevant information in the data source ",(0,i.kt)("inlineCode",{parentName:"p"},"yaml")," file and execute the same dmctl command to load the corresponding data source into the DM cluster."))),(0,i.kt)("h3",{id:"configure-migration-tasks"},"Configure migration tasks"),(0,i.kt)("ol",null,(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Edit task configuration file ",(0,i.kt)("inlineCode",{parentName:"p"},"task.yaml"),", which can refer to ",(0,i.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb-data-migration/v2.0/migrate-data-using-dm#step-4-configure-the-data-migration-task"},"Configure the data migration task"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"Configure the ",(0,i.kt)("inlineCode",{parentName:"p"},"target-database.host")," in ",(0,i.kt)("inlineCode",{parentName:"p"},"task.yaml")," as the TiDB host address that the Kubernetes cluster can access internally. If the cluster is deployed by TiDB Operator, configure the host as ",(0,i.kt)("inlineCode",{parentName:"p"},"${tidb_cluster_name}-tidb.${namespace}"),".")),(0,i.kt)("li",{parentName:"ol"},(0,i.kt)("p",{parentName:"li"},"In the ",(0,i.kt)("inlineCode",{parentName:"p"},"task.yaml")," file, take the following steps:"),(0,i.kt)("ul",{parentName:"li"},(0,i.kt)("li",{parentName:"ul"},"Add the ",(0,i.kt)("inlineCode",{parentName:"li"},"loaders.${customized_name}.dir")," field as the import and export directory for the full volume data, where ",(0,i.kt)("inlineCode",{parentName:"li"},"${customized_name}")," is a name that you can customize."),(0,i.kt)("li",{parentName:"ul"},"Configure the ",(0,i.kt)("inlineCode",{parentName:"li"},"loaders.${customized_name}.dir")," field as the subdirectory of the persistent volume in the Pod ",(0,i.kt)("inlineCode",{parentName:"li"},"/var/lib/dm-worker")," directory. For example, ",(0,i.kt)("inlineCode",{parentName:"li"},"/var/lib/dm-worker/dumped_data"),"."),(0,i.kt)("li",{parentName:"ul"},"Reference ",(0,i.kt)("inlineCode",{parentName:"li"},"${customized_name}")," in the instance configuration. For example, ",(0,i.kt)("inlineCode",{parentName:"li"},'mysql-instances[0].loader-config-name: "{customized_name}"'),".")))),(0,i.kt)("h3",{id:"startcheckstop-the-migration-tasks"},"Start/Check/Stop the migration tasks"),(0,i.kt)("p",null,"Refer to the corresponding steps in ",(0,i.kt)("a",{parentName:"p",href:"https://docs.pingcap.com/tidb-data-migration/v2.0/migrate-data-using-dm#step-5-start-the-data-migration-task"},"Migrate Data Using DM")," and fill in the master-addr as ",(0,i.kt)("inlineCode",{parentName:"p"},"${dm_cluster_name}-dm-master:8261"),"."))}u.isMDXComponent=!0}}]);